{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import zipfile\n",
    "\n",
    "# url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
    "# file_name = \"horse-or-human.zip\"\n",
    "# training_dir = 'horse-or-human/training/'\n",
    "# urllib.request.urlretrieve(url, file_name)\n",
    "# zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "# zip_ref.extractall(training_dir)\n",
    "# zip_ref.close()\n",
    "\n",
    "\n",
    "### This code was unable to work because the website no longer exists\n",
    "### I manually downloaded the folder and attached it to this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import RMSprop\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "from PIL import Image\n",
    "# sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "training_dir = '/Users/samin/Desktop/ML-Projects/tensorflow_practice/data/horse-or-human/train'\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    training_dir,\n",
    "                    target_size=(300, 300),\n",
    "                    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val_dir = '/Users/samin/Desktop/ML-Projects/tensorflow_practice/data/horse-or-human/validation'\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                    val_dir,\n",
    "                    target_size=(300, 300),\n",
    "                    class_mode = 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     featurewise_center=False,\n",
    "#     samplewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     samplewise_std_normalization=False,\n",
    "#     zca_whitening=False,\n",
    "#     zca_epsilon=1e-06,\n",
    "#     rotation_range=0,\n",
    "#     width_shift_range=0.0,\n",
    "#     height_shift_range=0.0,\n",
    "#     brightness_range=None,\n",
    "#     shear_range=0.0,\n",
    "#     zoom_range=0.0,\n",
    "#     channel_shift_range=0.0,\n",
    "#     fill_mode='nearest',\n",
    "#     cval=0.0,\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False,\n",
    "#     rescale=None,\n",
    "#     preprocessing_function=None,\n",
    "#     data_format=None,\n",
    "#     validation_split=0.0,\n",
    "#     interpolation_order=1,\n",
    "#     dtype=None\n",
    "# )\n",
    "\n",
    "# ALl the parameters we can tweak for our input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/optimizers/legacy/rmsprop.py:144: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, (3,3), activation='relu' ,\n",
    "    input_shape=(300, 300, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    # keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(lr=0.001),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_generator, epochs=15, \n",
    "#                     validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/bqtpsjds1p16_p2clkzkw5d80000gn/T/ipykernel_45915/3862944308.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator, epochs=15,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 18s 530ms/step - loss: 0.6833 - accuracy: 0.6865 - val_loss: 0.9657 - val_accuracy: 0.7773\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - 17s 510ms/step - loss: 0.2555 - accuracy: 0.9133 - val_loss: 0.4934 - val_accuracy: 0.8828\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - 17s 505ms/step - loss: 0.2646 - accuracy: 0.9211 - val_loss: 1.4624 - val_accuracy: 0.8008\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - 17s 519ms/step - loss: 0.2867 - accuracy: 0.9435 - val_loss: 0.8409 - val_accuracy: 0.8477\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - 18s 542ms/step - loss: 0.0935 - accuracy: 0.9805 - val_loss: 2.3660 - val_accuracy: 0.7773\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - 18s 528ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 2.4384 - val_accuracy: 0.8125\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - 17s 514ms/step - loss: 0.0909 - accuracy: 0.9679 - val_loss: 0.7728 - val_accuracy: 0.8242\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - 17s 505ms/step - loss: 0.0854 - accuracy: 0.9854 - val_loss: 1.9148 - val_accuracy: 0.8320\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - 17s 511ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.3769 - val_accuracy: 0.8477\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - 17s 509ms/step - loss: 1.4251e-04 - accuracy: 1.0000 - val_loss: 6.2087 - val_accuracy: 0.8047\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - 17s 513ms/step - loss: 1.9060 - accuracy: 0.9766 - val_loss: 3.0824 - val_accuracy: 0.7891\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - 17s 517ms/step - loss: 6.8741e-04 - accuracy: 1.0000 - val_loss: 2.9933 - val_accuracy: 0.8281\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - 18s 535ms/step - loss: 3.0900e-05 - accuracy: 1.0000 - val_loss: 3.5542 - val_accuracy: 0.8281\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - 18s 545ms/step - loss: 8.9546e-06 - accuracy: 1.0000 - val_loss: 4.2610 - val_accuracy: 0.8281\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - 18s 534ms/step - loss: 1.0794e-06 - accuracy: 1.0000 - val_loss: 4.5309 - val_accuracy: 0.8281\n"
     ]
    }
   ],
   "source": [
    "# Use .fit_generator for large datasets or when data augmentation needs to be applied\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=15, \n",
    "                    validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 149, 149, 16)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 73, 73, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 35, 35, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1704097 (6.50 MB)\n",
      "Trainable params: 1704097 (6.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
